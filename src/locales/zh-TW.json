{
  "nav": {
    "products": "產品",
    "gpus": "GPU",
    "studio": "工作室",
    "pricing": "定價",
    "developers": "開發者",
    "company": "公司",
    "login": "登入",
    "contactSales": "聯絡銷售"
  },
  "products": {
    "gpuCompute": "GPU 運算",
    "clusterEngine": "叢集引擎",
    "inferenceEngine": "推論引擎",
    "modelLibrary": "模型庫"
  },
  "gpus": {
    "h200": "NVIDIA H200",
    "gb200": "NVIDIA GB200 NVL72",
    "hgxb200": "NVIDIA HGX™ B200"
  },
  "company": {
    "aboutUs": "關於我們",
    "blog": "部落格",
    "discord": "Discord",
    "partners": "合作夥伴",
    "careers": "人才招募"
  },
  "common": {
    "learnMore": "了解更多",
    "getStarted": "立即開始",
    "deployNow": "立即部署",
    "applyNow": "立即申請",
    "joinNow": "立即加入",
    "subscribe": "訂閱",
    "new": "新",
    "viewModel": "查看模型",
    "contactSales": "聯絡銷售",
    "seeModelList": "查看模型列表",
    "showingModels": "顯示 {{count}} 個模型",
    "noModelsFound": "找不到符合條件的模型。",
    "active": "運行中",
    "viewPricing": "查看定價",
    "watchStory": "觀看故事",
    "viewAllArticles": "查看所有文章",
    "submit": "提交",
    "startNow": "立即開始",
    "reserve": "立即預訂"
  },
  "footer": {
    "subscribeNewsletter": "訂閱我們的電子報",
    "enterEmail": "輸入電子郵件",
    "gpuCloud": "GPU 雲端",
    "clusterEngine": "叢集引擎",
    "inferenceEngine": "推論引擎",
    "pricing": "定價",
    "modelLibrary": "模型庫",
    "glossary": "詞彙表",
    "blog": "部落格",
    "careers": "人才招募",
    "aboutUs": "關於我們",
    "partners": "合作夥伴",
    "contactUs": "聯絡我們",
    "privacyPolicy": "隱私政策",
    "termsOfUse": "使用條款",
    "allRightsReserved": "© 2025 版權所有。"
  },
  "home": {
    "heroTitle": "無限制地建構 AI",
    "heroSubtitle": "我們打造完整的 GPU 基礎設施，讓您專注於真正重要的事——您的 AI。",
    "getStarted": "立即開始",
    "viewPricing": "查看定價",
    "foundationTitle": "您 AI 成功的基石",
    "foundationSubtitle": "— 由 GPU 雲端解決方案驅動",
    "foundationDescription": "NexusAI 提供您建構可擴展 AI 解決方案所需的一切——完全運行在 NexusAI 自有的 AI 優化數據中心。從高效能推論和容器化運維，到隨需存取頂級 GPU 進行訓練和推論，我們掌控完整技術堆疊。",
    "inferenceTitle": "推論引擎 Inference Engine",
    "inferenceDescription1": "NexusAI 推論引擎為開發者提供運行 AI 模型所需的超高速度與彈性擴展性，專為極低延遲、高併發處理以及頂尖效能優化設計。無論是深度學習、自然語言處理 (NLP) 還是計算機視覺 (CV)，皆能完美支援，實現更高的推論效率。",
    "inferenceDescription2": "透過 NexusAI 的全球 GPU 節點佈局，開發者能夠即時部署模型，隨時隨地擴展計算力，自動化調整運算負載，大幅降低成本並提升效能。依需求彈性伸縮，即刻應對高流量運算挑戰，交付更快、更穩定且更精準的 AI 預測。",
    "inferenceModelsLabel": "輕鬆運行市場領先的 AI 模型",
    "clusterTitle": "Cluster Engine",
    "clusterDescription": "NexusAI 的 Cluster Engine 是您的一站式 AI 雲端管理平台，專為簡化 GPU 資源協調、工作負載排程和成本優化而設計。無論您是管理 AI 訓練、微調還是推論工作負載，Cluster Engine 都能提供即時可見性和控制。",
    "gpuTitle": "GPUs",
    "gpuDescription": "NexusAI 提供多元的 NVIDIA GPU 組合，專為 AI/ML 訓練、推論和數據分析設計。我們的 GPU 基礎設施專為最嚴苛的 AI 工作負載打造，具備超低延遲、高記憶體頻寬和企業級可靠性。",
    "caseStudyTitle": "實證成效",
    "caseStudySubtitle": "我們的客戶在成本、效能和上市時間方面都取得了可衡量的改善。",
    "caseStudyQuote": "NexusAI 徹底改變了我們部署 AI 模型的方式。過去需要數週的工作現在只需數小時。",
    "costSavings": "成本節省",
    "costSavingsDesc": "基礎設施成本平均降低",
    "fasterDeployment": "更快部署",
    "fasterDeploymentDesc": "新 GPU 叢集從數週縮短至數小時",
    "newsTitle": "最新洞見",
    "newsSubtitle": "掌握 AI 基礎設施和 GPU 運算的最新動態。",
    "ctaTitle": "準備好大規模部署 AI 了嗎？",
    "ctaSubtitle": "加入數千家使用 NexusAI 驅動 AI 基礎設施的企業。只需幾分鐘即可開始。"
  },
  "faq": {
    "title": "常見問題",
    "subtitle": "關於我們 GPU 基礎設施平台您需要知道的一切。",
    "items": {
      "q1": {
        "question": "你們提供哪些 GPU 型號？",
        "answer": "我們提供最新的 NVIDIA GPU，包括 H100、A100 和 L40S。所有叢集都配備 NVLink 和 InfiniBand，在分散式訓練和推論工作負載中實現最佳效能。"
      },
      "q2": {
        "question": "部署新叢集需要多長時間？",
        "answer": "大多數叢集可以在數小時內完成配置，而非數週。我們的自動化基礎設施允許根據您的需求快速擴展，並為熱門的 ML 框架預先配置環境。"
      },
      "q3": {
        "question": "你們有哪些安全認證？",
        "answer": "我們維持 SOC 2 Type II、HIPAA 和 GDPR 合規性。所有資料在靜態和傳輸中都經過加密，並提供可選的專用租戶以實現最大隔離。"
      },
      "q4": {
        "question": "我可以使用自己的模型嗎？",
        "answer": "當然可以。我們的平台支援任何模型格式，包括 PyTorch、TensorFlow 和 ONNX。我們還為 Llama、Mistral 等熱門開源模型提供優化的服務基礎設施。"
      },
      "q5": {
        "question": "計費方式是什麼？",
        "answer": "我們提供靈活的定價方式，包括隨需、預留容量和承諾使用折扣。您只需為使用的運算資源付費，價格透明無隱藏費用。"
      }
    }
  },
  "news": {
    "articles": {
      "article1": {
        "title": "擴展 AI 基礎設施：來自 10,000 個 GPU 的經驗",
        "excerpt": "企業團隊如何以前所未有的規模管理 GPU 叢集。",
        "category": "工程"
      },
      "article2": {
        "title": "推論的未來：H100 vs A100 效能評測",
        "excerpt": "生產環境 AI 工作負載的真實效能比較。",
        "category": "研究"
      },
      "article3": {
        "title": "AI 團隊的成本優化策略",
        "excerpt": "降低 GPU 基礎設施成本最高達 50% 的實用技巧。",
        "category": "商業"
      }
    }
  },
  "cluster": {
    "centralizedManagement": "集中式管理",
    "centralizedManagementDesc": "在單一直觀的儀表板中統一管理跨多個區域的 GPU 資源和工作負載。",
    "realtimeDashboard": "即時儀表板",
    "realtimeDashboardDesc": "監控效能指標、追蹤資源使用率，並即時獲取基礎設施異常警報。",
    "accessManagement": "存取管理",
    "accessManagementDesc": "透過角色型存取控制和團隊工作區，安全地管理使用者權限和 GPU 資源存取。",
    "activeGPUs": "運行中的 GPU",
    "lastUpdated": "最後更新：剛剛",
    "avgGPUUsage": "平均 GPU 使用率",
    "activeNodes": "活躍節點",
    "memoryUsed": "已用記憶體",
    "uptime": "正常運行時間",
    "teamMembers": "團隊成員",
    "invite": "+ 邀請"
  },
  "gpu": {
    "topTierGPUs": "頂級 GPU",
    "topTierGPUsDesc": "以具競爭力的價格和保證可用性，存取最新的 NVIDIA H100 和 A100 GPU。",
    "infinibandNetworking": "InfiniBand 網路",
    "infinibandNetworkingDesc": "超低延遲互連，400Gb/s 頻寬，適用於分散式訓練和即時推論。",
    "secureScalable": "安全且可擴展",
    "secureScalableDesc": "企業級安全性，符合 SOC 2 Type II、HIPAA 和 GDPR。可從 1 擴展至 1000+ GPU。"
  },
  "pricing": {
    "title": "定價",
    "subtitle": "有競爭力的透明價格彈性計費 — 為現代化 AI 部署量身打造",
    "gpuPlans": {
      "h200": {
        "label": "最高性能",
        "description": "適用於大規模訓練需求、最強大算力的選項。搭載 HBM3e 記憶體，提供無與倫比的 AI 訓練效能。",
        "cta": "聯繫我們"
      },
      "h100": {
        "label": "效能與成本兼備",
        "description": "適合大量推理任務需求，具備成本效益的最佳化選項。80GB HBM3 記憶體，滿足企業級 AI 部署。",
        "cta": "立即部署"
      },
      "blackwell": {
        "label": "即將推出",
        "headline": "搶先預訂",
        "description": "Blackwell 將於 2025 年上市，具備更高能效和 AI 優化特性，適合下一代 AI 工作負載。",
        "cta": "立即預訂"
      }
    },
    "serviceEngine": {
      "title": "強化您的 GPU 雲端運算",
      "subtitle": "打破效能瓶頸，全面加速 AI 訓練與推論。",
      "serviceType": "服務類型",
      "inference": {
        "title": "推論引擎 Inference Engine",
        "description": "NexusAI 的推論服務適用於需要高吞吐量和低延遲的場景。優化的推論堆疊確保模型能夠以最佳效能運行，支援即時 AI 應用。",
        "cta": "了解更多"
      },
      "cluster": {
        "title": "叢集引擎 Cluster Engine",
        "description": "NexusAI Cluster 服務優化於分佈式訓練和大規模計算。透過 InfiniBand 高速網路，實現多節點協同運算，加速大型模型訓練。",
        "cta": "開始部署"
      }
    },
    "cta": {
      "title": "不確定哪個產品適合您的需求？讓我們談談。",
      "subtitle": "我們的團隊隨時為您選擇合適的 GPU 雲端解決方案，解答您關於效能、定價或擴展的任何問題。"
    },
    "faq": {
      "title": "常見問題",
      "subtitle": "對我們提供的服務有疑問嗎？請參閱以下常見問題",
      "items": {
        "q1": {
          "question": "提供哪些類型的 GPU？",
          "answer": "我們提供最新的 NVIDIA GPU，包括 H200（具備 HBM3e 記憶體）、H100 80GB HBM3 和 A100 80GB HBM2e。所有配置都包含 NVLink 和 InfiniBand，以實現最佳的分散式訓練性能。"
        },
        "q2": {
          "question": "如何計費和付款？",
          "answer": "我們採用按需計費模式，按 GPU 小時計算。您可以選擇預付費或後付費方案，支援信用卡、銀行轉帳等多種付款方式。企業客戶可享有專屬付款條件。"
        },
        "q3": {
          "question": "是否提供大量折扣？",
          "answer": "是的！我們提供彈性的折扣方案。包括長期訂閱折扣（最高可達 40%）、大量使用折扣，以及企業專屬定價。請聯繫我們的銷售團隊了解詳情。"
        },
        "q4": {
          "question": "可以隨時調整資源嗎？",
          "answer": "當然可以。您可以隨時透過控制台或 API 增加或減少 GPU 資源。我們的彈性架構支援即時擴展，確保您只為實際使用的資源付費。"
        },
        "q5": {
          "question": "如何開始使用？",
          "answer": "開始使用非常簡單。聯繫我們的銷售團隊進行諮詢，我們會協助您確定適合需求的配置。大多數集群可在數小時內完成配置，我們提供完整的入門支援。"
        }
      }
    }
  },
  "gpuPage": {
    "heroTitle": "GPU 算力租賃",
    "heroSubtitle": "完整雲端整合的裸機伺服器，以最具競爭力的價格提供。",
    "features": {
      "onDemand": {
        "title": "彈性 On-Demand GPU 服務",
        "description": "即時使用 NVIDIA GPU 算力，快速部署您的運算需求。我們的可擴展平台讓您依需求自由調整資源配置，完美支援 AI 與機器學習任務。價格實惠且無長期合約限制，讓您享有最大的使用彈性，無需預付成本。"
      },
      "hardware": {
        "title": "頂尖硬體規格",
        "description": "配備 3.2 Tbps InfiniBand 網路，為分散式訓練提供極速連線；搭載 NVIDIA H100 GPU的先進訓練叢集，釋放極致運算力。簡單的 SSH 連線、資料集下載，立即開始您的AI之旅。"
      },
      "privateCloud": {
        "title": "企業專屬私有雲",
        "description": "NexusAI 提供專屬於企業的雲端環境，確保端到端的安全與資料隔離。可客製化的環境配置滿足企業獨特的IT 策略。您可以依自己的方式建置、同時擁有完整的控制與彈性，在雲端與本地環境之間無縫切換。"
      },
      "security": {
        "title": "安全網路架構",
        "description": "我們以高 InfiniBand 網路效能為基礎打造穩定、高效的跨區域無縫連接網路，使應用程式或應用可乘載最佳承載，透過嚴格限制了網絡閒間的存取維護安全性。"
      },
      "selectHardware": "選擇硬體資源",
      "numGpus": "GPU 數量",
      "numCpus": "CPU 數量",
      "ram": "記憶體",
      "ephemeralStorage": "暫存空間"
    }
  },
  "h200Page": {
    "hero": {
      "price": "起價 $2.15 / GPU-小時",
      "title": "使用 NVIDIA H200 雲端 GPU 加速 AI 創新",
      "description": "NVIDIA H200 Tensor Core GPU 以顛覆性的效能和記憶體能力，為生成式 AI 和高效能運算 (HPC) 工作負載提供強力支援。配備 141GB HBM3e 記憶體和 4.8TB/s 頻寬，為大型語言模型推論提供前所未有的吞吐量。",
      "cta": "立即部署"
    },
    "features": {
      "memory": {
        "title": "更高的記憶體容量",
        "description": "H200 配備 141GB HBM3e 記憶體，容量幾乎是 H100 的兩倍，使處理更大的模型和數據集成為可能，不再受記憶體限制。"
      },
      "bandwidth": {
        "title": "增強的記憶體頻寬",
        "description": "H200 擁有 4.8 TB/s 的記憶體頻寬，比 H100 高出 1.4 倍，大幅加速資料傳輸和處理任務。"
      },
      "performance": {
        "title": "強化的 AI 效能",
        "description": "H200 針對生成式 AI 和大型語言模型進行優化，為 Llama 2 70B 等模型提供高達 1.9 倍的推論效能提升。"
      }
    },
    "chart": {
      "title": "效能比較：H100 vs H200",
      "benchmark1": "Llama 2 70B 推論 (tokens/秒)",
      "benchmark2": "Llama 2 70B (FP8) 推論 (tokens/秒)",
      "resultsTitle": "基準測試結果",
      "resultsP1": "NVIDIA H200 在實際 AI 推論工作負載中展示出比 H100 顯著的效能提升。在 Llama 2 70B 推論基準測試中，H200 提供",
      "resultsP1Highlight": "1.4 倍更快的吞吐量",
      "resultsP1End": "。",
      "resultsP2": "使用 FP8 精度時，效能提升更為顯著。H200 達到",
      "resultsP2Highlight": "1.9 倍更快的推論",
      "resultsP2End": "，使其成為需要兼顧速度和效率的生產 AI 部署的理想選擇。",
      "resultsP3": "這些改進得益於 H200 增強的 HBM3e 記憶體架構，提供 4.8 TB/s 的頻寬——對於記憶體密集型的大型語言模型運算至關重要。"
    },
    "marketing": {
      "title": "與 NexusAI 和 H200 一起面向未來",
      "description": "隨著 AI 模型持續增長規模和複雜度，NVIDIA H200 為您提供領先所需的發展空間。憑藉其龐大的 141GB 記憶體容量和業界領先的頻寬，NexusAI 上的 H200 確保您的基礎設施能夠應對明日的 AI 工作負載。透過我們的企業級雲端平台，從開發無縫擴展到生產環境。",
      "cta": "立即預訂"
    },
    "cta": {
      "title": "不要錯過部署全球最強大 GPU 資源的機會。",
      "button": "聯絡我們"
    }
  },
  "gb200Page": {
    "hero": {
      "title": "NVIDIA GB200 NVL72 的下一代 AI 加速",
      "description": "專為最苛刻的企業工作負載設計的先進 AI 基礎設施。GB200 NVL72 結合 Grace CPU 和 Blackwell GPU，提供前所未有的效能。",
      "cta": "立即開始"
    },
    "features": {
      "sectionTitle": "賦能 AI 創新",
      "sectionDescription": "NVIDIA GB200 NVL72 代表 AI 運算的巨大飛躍，將最先進的 GPU 架構與專為企業級部署打造的基礎設施完美結合。",
      "items": {
        "performance": {
          "title": "無與倫比的 AI 效能",
          "description": "結合 Grace CPU 和 Blackwell GPU，實現前所未有的運算密度和效率，為 AI 訓練和推論提供突破性效能。"
        },
        "dataProcessing": {
          "title": "企業 AI 的頂級資料處理",
          "description": "輕鬆處理數萬億參數模型，使企業能夠應對最複雜的 AI 挑戰，不受基礎設施限制。"
        },
        "scalability": {
          "title": "LLM 和 AI 工作負載的頂級可擴展性",
          "description": "透過 NVLink 互連從單節點擴展至數千節點，隨著 AI 需求增長提供無縫擴展。"
        },
        "efficiency": {
          "title": "節能架構",
          "description": "優化的每 FLOP 功耗意味著更低的營運成本，同時維持峰值效能，實現可持續的 AI 基礎設施。"
        }
      },
      "cta": "聯繫銷售"
    },
    "solutions": {
      "title": "為您的 AI 需求量身打造的 GPU 雲端解決方案",
      "training": {
        "title": "AI 訓練基礎設施",
        "description": "配備高速 NVLink 連接的專用 AI 訓練基礎設施，實現數千個 GPU 間的分散式訓練，延遲極低。"
      },
      "inference": {
        "title": "生產推論",
        "description": "針對生產 AI 應用優化的低延遲推論解決方案，為關鍵任務工作負載提供即時回應。"
      },
      "scaling": {
        "title": "彈性擴展",
        "description": "從單一 GPU 到多節點叢集的彈性擴展選項，按需配置以適應您的工作負載需求。"
      }
    },
    "futureProof": {
      "title": "與 NexusAI 和 GB200 NVL72 一起面向未來",
      "description": "隨著 AI 模型持續增長複雜度，GB200 NVL72 確保您的基礎設施始終領先。憑藉其突破性架構和無縫可擴展性，您可以自信地投資明日的 AI 能力。NexusAI 提供平台，以企業級可靠性和支援駕馭這股力量。",
      "cta": "了解更多"
    },
    "contact": {
      "title": "聯絡我們",
      "subtitle": "與我們的團隊聯繫，獲取更多資訊",
      "name": "姓名",
      "company": "公司",
      "email": "電子郵件",
      "phone": "電話號碼",
      "message": "訊息",
      "submit": "發送訊息",
      "successTitle": "訊息已送出！",
      "successMessage": "我們會盡快回覆您。"
    }
  },
  "hgxb200Page": {
    "hero": {
      "title": "釋放 NVIDIA HGX™ B200 的強大力量",
      "description": "為複雜模型和企業級 AI 部署提供頂級效能。終極 8-GPU 平台，適用於 AI 訓練和推論。",
      "cta": "聯繫銷售",
      "learnMore": "了解更多"
    },
    "features": {
      "sectionTitle": "下一代 AI 運算",
      "sectionDescription": "NVIDIA HGX B200 平台代表 AI 基礎設施的巔峰，結合 8 個 Blackwell 架構 GPU 與先進的 NVLink 互連技術。專為推動人工智慧邊界的組織設計，從訓練前沿模型到大規模部署即時推論。",
      "items": {
        "performance": {
          "title": "針對 AI 訓練和推論優化的 GPU 效能",
          "description": "HGX B200 透過第 5 代 NVLink 連接 8 個 Blackwell GPU，提供前所未有的運算密度，實現 1.8TB/s 的 GPU 對 GPU 頻寬，無縫並行處理。"
        },
        "architecture": {
          "title": "適用於苛刻 AI 工作負載的高擴展架構",
          "description": "專為數萬億參數模型和企業 AI 部署打造。統一記憶體架構可高效處理最大型的基礎模型。"
        },
        "scalability": {
          "title": "無縫 AI 可擴展性",
          "description": "連接多個 HGX B200 系統實現機架級 AI 超級運算。NVLink Switch 為最苛刻的訓練工作負載提供數千個 GPU 的線性擴展。"
        }
      },
      "datasheet": "查看 NVIDIA HGX B200 平台規格書"
    },
    "solutions": {
      "title": "為您的 AI 需求量身打造的彈性 GPU 解決方案",
      "onDemand": {
        "title": "隨需存取",
        "description": "彈性按小時計費，適用於實驗和開發工作負載，即時配置。非常適合探索新模型架構或執行定期訓練任務的團隊。"
      },
      "reserved": {
        "title": "預留容量",
        "description": "為長期 AI 專案提供折扣定價，保證可用性和效能。適合需要可預測運算資源的生產工作負載。"
      },
      "dedicated": {
        "title": "專屬叢集",
        "description": "為大規模訓練提供 HGX B200 系統的自訂配置，配備專用網路和儲存。專為訓練前沿 AI 模型的組織設計。"
      }
    },
    "elevate": {
      "title": "與 NexusAI 和 NVIDIA HGX B200 提升您的 AI 能力",
      "description": "透過 NexusAI 的企業基礎設施，善用全球最強大的 AI 平台。無需資本投資即可立即存取 HGX B200 系統，並獲得 24/7 支援和優化的 MLOps 工具，加速價值實現。",
      "cta": "申請存取"
    },
    "contact": {
      "title": "聯絡我們",
      "subtitle": "與我們的團隊聯繫，獲取更多資訊",
      "name": "姓名",
      "company": "公司",
      "email": "電子郵件",
      "phone": "電話號碼",
      "message": "訊息",
      "submit": "發送訊息",
      "successTitle": "訊息已送出！",
      "successMessage": "我們會盡快回覆您。"
    }
  },
  "contact": {
    "title": "聯絡我們",
    "subtitle": "與我們的團隊聯繫，獲取更多資訊和支援。",
    "sales": {
      "title": "銷售",
      "description": "聯繫我們的銷售團隊，了解更多關於我們的產品和定價。"
    },
    "support": {
      "title": "技術支援",
      "description": "聯繫我們的支援團隊，獲取技術協助和客戶服務。"
    },
    "media": {
      "title": "媒體與新聞",
      "description": "如有媒體諮詢，請聯繫我們的新聞團隊。"
    },
    "form": {
      "firstName": "名字",
      "lastName": "姓氏",
      "email": "電子郵件",
      "interestType": "感興趣的類型",
      "selectOne": "請選擇...",
      "gpuCloud": "GPU 雲端服務",
      "inference": "推論引擎",
      "cluster": "叢集引擎",
      "enterprise": "企業解決方案",
      "partnership": "合作夥伴",
      "other": "其他",
      "company": "公司名稱",
      "submit": "提交",
      "successTitle": "訊息已送出！",
      "successMessage": "我們將在 24 小時內回覆您。"
    }
  },
  "about": {
    "kicker": "關於 NexusAI",
    "heroTitle": "築基 AI 基礎建設，成就每個可能",
    "heroSubtitle": "Building AI Infrastructure, Empowering Possibilities. 我們致力於打造最先進的 GPU 雲端運算平台，加速全球 AI 創新。",
    "stats": {
      "year": "年",
      "coreMembers": "核心成員",
      "globalOffices": "全球據點"
    }
  },
  "studio": {
    "heroTitle": "創意自在流動",
    "heroSubtitle": "您的智慧畫布，用於構思、迭代和塑造工作流程。",
    "startNow": "立即開始"
  },
  "modelLibrary": {
    "heroTitle": "模型庫",
    "heroSubtitle": "探索我們精選的強大開源模型庫，加速您的 AI 應用開發。",
    "filters": {
      "all": "全部",
      "llm": "大語言模型",
      "vision": "視覺",
      "video": "影片",
      "embedding": "向量嵌入"
    },
    "searchPlaceholder": "搜尋模型...",
    "ctaTitle": "不確定哪個產品適合您的需求？讓我們談談。",
    "ctaSubtitle": "我們的團隊隨時為您選擇適合 AI 應用的基礎設施和模型提供協助。",
    "types": {
      "textGeneration": "文字生成",
      "codeGeneration": "程式碼生成",
      "imageGeneration": "圖像生成",
      "visionLanguage": "視覺語言",
      "textEmbedding": "文字嵌入"
    }
  },
  "inferenceEngine": {
    "heroTitle": "NexusAI 雲端推論引擎",
    "heroSubtitle": "輕鬆運行和擴展生成式 AI 模型。部署預訓練模型，享受快速、低延遲的推論部署，具備您可以信賴的高速和可擴展性。",
    "cubeLabel": "推論",
    "cubeSubLabel": "引擎",
    "smarterWayTitle": "更智慧的推論方式",
    "features": {
      "deployment": {
        "title": "快速部署，零煩惱",
        "description": "透過全託管基礎設施即時擴展。我們的推論引擎提供所有您需要的自動化和工具，讓您更快交付，專注於建構。"
      },
      "efficiency": {
        "title": "效能最佳化",
        "description": "先進的 GPU 優化和模型快取技術，最小化延遲同時最大化吞吐量。透過我們智慧的資源分配，讓每一分錢獲得更多推論。"
      }
    },
    "modelShowcase": {
      "title": "預建 AI 模型，快速推論",
      "subtitle": "從我們精選的預優化模型庫中選擇，或帶上您自己的模型",
      "inference": "推論",
      "viewAllModels": "查看我們模型庫中的所有模型 →",
      "models": {
        "llama2": {
          "name": "Llama 2",
          "description": "用於文字生成和對話的開源大型語言模型"
        },
        "stableDiffusion": {
          "name": "Stable Diffusion",
          "description": "最先進的圖像生成模型"
        },
        "mpt7b": {
          "name": "MPT-7B",
          "description": "高效的商用 Transformer 模型"
        }
      }
    },
    "scaling": {
      "kicker": "自動擴展",
      "title": "輕鬆擴展您的 AI 工作負載",
      "description": "自動從零擴展到數千個並發請求。我們的智慧自動擴展根據流量模式即時調整資源。",
      "dynamicScaling": {
        "title": "動態擴展",
        "description": "隨著需求增加自動配置 GPU，在低峰期間縮減規模。"
      },
      "flexibility": {
        "title": "極致彈性",
        "description": "選擇您的最小和最大副本數，設定自訂擴展指標。"
      },
      "cta": "立即開始"
    },
    "monitoring": {
      "kicker": "監控",
      "title": "即時 AI 效能監控",
      "description": "透過全面的儀表板掌握脈動。即時追蹤延遲、吞吐量和錯誤率，確保最佳效能。",
      "totalInferences": "總推論次數",
      "avgLatency": "平均延遲",
      "throughput": "吞吐量",
      "uptime": "正常運行時間",
      "costPerInference": "每千次推論成本"
    },
    "cta": {
      "title": "立即開始推論",
      "subtitle": "幾分鐘內部署您的第一個模型。無需複雜設定。只需帶上您的模型，即可開始大規模提供預測服務。"
    },
    "faq": {
      "title": "常見問題",
      "subtitle": "快速獲得關於推論引擎的常見問題解答",
      "items": {
        "q1": {
          "question": "什麼是 NexusAI 雲端推論引擎？",
          "answer": "推論引擎是我們用於在生產環境中部署和擴展 AI 模型的託管平台。它處理所有基礎設施的複雜性，讓您可以專注於建構出色的 AI 應用程式。部署預訓練模型或帶上您自己的模型，只需最少的配置。"
        },
        "q2": {
          "question": "部署速度有多快？預期延遲是多少？",
          "answer": "預建模型的部署通常在 2 分鐘內完成。對於延遲，大多數模型可達到低於 100 毫秒的推論時間，優化後的 Llama 2 等模型對於典型請求可低至 30-50 毫秒。透過智慧快取最小化冷啟動。"
        },
        "q3": {
          "question": "如何優化效能和成本？",
          "answer": "我們的引擎使用 GPU 批次處理、模型快取和智慧請求路由來最大化吞吐量，同時最小化成本。自動擴展確保您只為使用的資源付費，在沒有流量時縮減至零。"
        },
        "q4": {
          "question": "自動擴展如何處理波動的流量？",
          "answer": "自動擴展器即時監控請求佇列深度、延遲和 GPU 使用率。當流量激增時，新副本在幾秒內啟動。在低峰期間，資源自動縮減。您可以配置最小/最大副本數和自訂擴展觸發器。"
        },
        "q5": {
          "question": "是否提供內建監控和運營洞察？",
          "answer": "是的！每個部署都包含一個綜合儀表板，提供即時指標：延遲百分位數、吞吐量、錯誤率、GPU 使用率和成本追蹤。設定異常警報並將資料匯出到您的可觀測性堆疊。"
        }
      }
    }
  },
  "clusterEngine": {
    "heroTitle": "NexusAI 雲端叢集引擎",
    "heroSubtitle": "大規模 AI 工作負載的自動化編排。以企業級的可靠性和效能部署、管理和監控 GPU 叢集。",
    "deployNow": "立即部署",
    "integrationTitle": "您的 AI 控制平面，用於叢集和容器編排",
    "integrationSubtitle": "與您現有的工具和基礎設施無縫整合",
    "features": {
      "scaling": {
        "title": "高效擴展",
        "description": "根據工作負載需求自動擴展或縮減您的 GPU 叢集。我們的智慧編排確保最佳資源利用率。"
      },
      "monitoring": {
        "title": "即時監控",
        "description": "透過全面的儀表板監控叢集的每個面向。即時追蹤執行個體健康狀況、資源使用情況和工作進度。"
      },
      "analytics": {
        "title": "使用分析",
        "description": "深入了解您的運算使用模式。視覺化趨勢、優化成本，並做出資料驅動的基礎設施決策。"
      },
      "resources": {
        "title": "資源管理",
        "description": "對每個 GPU、節點和容器進行精細控制。透過我們直觀的管理介面，精確地將資源分配到需要的地方。"
      },
      "security": {
        "title": "企業級安全",
        "description": "為您的 AI 工作負載提供銀行級安全性。角色型存取控制、靜態和傳輸中加密，以及全面的稽核日誌。"
      }
    },
    "ctaTitle": "準備好擴展您的 AI 基礎設施了嗎？",
    "ctaSubtitle": "立即開始使用叢集引擎，體驗企業級編排。",
    "darkCtaTitle": "輕鬆管理工作負載",
    "darkCtaSubtitle": "使用我們直觀的叢集引擎部署、監控和擴展您的 AI 工作負載。專為要求可靠性的團隊打造。",
    "faqTitle": "常見問題",
    "faqSubtitle": "關於叢集引擎的所有資訊"
  },
  "careers": {
    "heroTitle": "與 NexusAI 一起打造 AI 的未來",
    "heroSubtitle": "在 NexusAI，我們不僅僅是在建設尖端的雲端基礎設施——我們正在塑造 AI 和高效能運算的未來。當傑出人才擁有突破界限的自由時，創新就會蓬勃發展，這就是為什麼我們培養一個充滿活力、快節奏的環境，讓創造力和專業知識推動進步。",
    "joinButton": "加入 NexusAI",
    "seePositions": "查看職缺",
    "valuesKicker": "我們提供的不只是工作——我們提供的是塑造 AI 未來的機會。",
    "values": {
      "engineering": {
        "title": "工程卓越",
        "description": "建構突破可能性極限的複雜尖端技術。如果您是一位在創新中茁壯成長的工程師，這裡是您真正測試技能和成長的地方。"
      },
      "business": {
        "title": "商業前沿",
        "description": "加入一群大膽思考者的團隊，從零開始規劃全球業務。我們正在尋找準備好在快速發展的行業中產生真正影響的傑出問題解決者。"
      },
      "startup": {
        "title": "新創能量，遠大抱負",
        "description": "我們行動迅速、重視新想法，並相信大膽的飛躍。在 NexusAI Cloud，主動性、速度和創新不僅受到鼓勵——它們是必不可少的。"
      }
    },
    "officesKicker": "我們的團隊站在全球 AI 發展的前沿。",
    "joinTeamTitle": "加入全球創新者團隊",
    "joinTeamSubtitle": "我們希望匯聚來自世界各地的大膽思考者，共同推動 AI 和高效能運算的未來。我們多元、多文化的團隊在協作、新視角和對突破界限的共同熱情中蓬勃發展。"
  },
  "partners": {
    "heroTitle": "加入 NexusAI 合作夥伴計畫",
    "heroSubtitle": "加入強大的技術領導者生態系統，推動 AI 基礎設施的成長和創新。",
    "stats": {
      "founded": "成立年份",
      "partners": "合作夥伴",
      "gpuHours": "GPU 運算時數"
    },
    "diverseTitle": "多元夥伴，量身成功",
    "whyJoinTitle": "為什麼加入 NexusAI 合作夥伴計畫？",
    "benefits": {
      "access": {
        "title": "獨家存取",
        "description": "優先存取新的 GPU 基礎設施、測試版功能和專屬支援管道。"
      },
      "marketing": {
        "title": "聯合行銷",
        "description": "透過聯合行銷活動、案例研究和合作夥伴焦點專題放大您的品牌。"
      },
      "support": {
        "title": "技術支援",
        "description": "獲得專屬技術資源、培訓材料和優先工程支援。"
      }
    },
    "newProductTitle": "新產品",
    "faqTitle": "常見問題"
  },
  "blog": {
    "heroTitle": "NexusAI 部落格",
    "heroSubtitle": "探索我們團隊的最新消息、更新和見解。"
  },
  "models": {
    "deepseekR1": {
      "description": "開源推理模型，可與 OpenAI o1 媲美，在數學、程式設計和多步驟推理方面表現出色。"
    },
    "deepseekR1Distill": {
      "description": "免費端點體驗強大的推理模型，此蒸餾版本保留了出色的推理能力。"
    },
    "llama33": {
      "description": "開源推理模型，支援多語言對話優化，專為對話流暢度而調優。"
    },
    "free": "免費"
  },
  "gpuFaq": {
    "title": "常見問題",
    "subtitle": "快速取得常見問題的解答",
    "items": {
      "q1": {
        "question": "提供哪些類型的 GPU？",
        "questionEn": "What types of GPUs do you offer?",
        "answer": "我們提供最新的 NVIDIA GPU，包括 H100（80GB HBM3 記憶體）、H200（HBM3e 記憶體）和即將推出的 Blackwell 系列。所有配置都包含 NVLink 和 InfiniBand，以實現最佳的分散式訓練效能。"
      },
      "q2": {
        "question": "如何管理 GPU 叢集和網路以進行分散式訓練？",
        "questionEn": "How do I manage GPU clusters for distributed training?",
        "answer": "我們的平台包含全面的叢集管理儀表板。您可以透過我們的網頁主控台或 API 來配置節點、監控使用率、設定網路和管理作業。我們也支援 Kubernetes 和 Slurm 等流行的編排工具。"
      },
      "q3": {
        "question": "支援哪些軟體和深度學習框架？可以客製化嗎？",
        "questionEn": "Which deep learning frameworks are supported? Can I customize?",
        "answer": "我們支援所有主要框架，包括 PyTorch、TensorFlow、JAX 和 ONNX。您可以使用我們預先配置的容器，或自帶 Docker 映像。我們還提供優化版本以實現最大 GPU 使用率。"
      },
      "q4": {
        "question": "GPU 的價格方案如何？有提供成本最佳化功能嗎？",
        "questionEn": "What are the pricing options? Do you offer cost optimization?",
        "answer": "我們提供靈活的定價方案，包括按需計時費率、具有大幅折扣的預留容量，以及承諾使用合約。我們的平台內建成本優化工具，幫助您在最大化效能的同時將支出降到最低。"
      }
    }
  },
  "developers": {
    "demoApps": "示範應用",
    "docsHubLabel": "文件中心",
    "docsHub": {
      "badge": "技術文件",
      "title": "文件中心",
      "subtitle": "完整的指南、API 參考文件和資源，協助您使用 NexusAI 建構應用。",
      "earlyAccess": "申請早期存取",
      "exploreDemos": "探索示範應用"
    },
    "demoHero": {
      "badge": "示範",
      "title": "開發者示範應用",
      "subtitle": "在 NexusAI 上探索和測試即時 AI 模型。建構原型、進行實驗，並將生成式 AI 整合到您的應用程式中。"
    },
    "demoAppsContent": {
      "ragChatbot": {
        "title": "多模態 RAG 聊天機器人",
        "description": "智慧多模態 RAG 聊天機器人，提供自然問答功能、生成式回答和互動視覺化，適用於問答、摘要和多媒體工作流程。"
      },
      "deepResearch": {
        "title": "深度研究代理",
        "description": "長文本代理，分析來源並產生結構化、基於引用的報告——複雜研究的捷徑推理。"
      },
      "companyResearch": {
        "title": "企業研究代理",
        "description": "專門用於企業分析的代理，綜合資金、產品、競爭對手和市場定位，為業務增長提供敘事基礎。"
      }
    },
    "demoTags": {
      "rag": "RAG",
      "chatbot": "聊天機器人",
      "qa": "問答",
      "pdfUpload": "PDF 上傳",
      "multimedia": "多媒體",
      "knowledgeGrounding": "知識基礎",
      "aiAssistant": "AI 助手",
      "research": "研究",
      "longContext": "長文本",
      "summarization": "摘要",
      "analysis": "分析",
      "citations": "引用",
      "multiDocument": "多文件",
      "knowledgeSynthesis": "知識綜合",
      "companyResearch": "企業研究",
      "businessIntelligence": "商業智慧",
      "competitorAnalysis": "競爭分析",
      "webGeneration": "網頁生成",
      "salesEnablement": "銷售賦能",
      "marketResearch": "市場研究"
    },
    "readyBanner": {
      "title": "準備好建構了嗎？",
      "subtitle": "探索強大的 AI 模型，只需幾次點擊即可啟動您的專案。"
    },
    "link": "連結",
    "code": "程式碼",
    "docsHub": {
      "badge": "文件",
      "title": "文件中心",
      "subtitle": "全面的文件、API 參考和整合指南，幫助您使用 NexusAI 進行建構。即將推出。",
      "earlyAccess": "搶先體驗",
      "exploreDemos": "探索示範應用"
    }
  },
  "h200Faq": {
    "title": "常見問題",
    "subtitle": "關於 NexusAI 上的 NVIDIA H200 您需要知道的一切",
    "items": {
      "q1": {
        "question": "NexusAI 提供的 NVIDIA H200 GPU 是什麼？",
        "answer": "NVIDIA H200 是 NVIDIA 最新的高效能 GPU，配備 141GB HBM3e 記憶體和 4.8 TB/s 頻寬。NexusAI 在我們的企業級雲端基礎設施中提供 H200 GPU 的隨需存取，讓您無需資本投資即可運行最苛刻的 AI 和 HPC 工作負載。"
      },
      "q2": {
        "question": "H200 與之前的 GPU 型號（如 H100）有何不同？",
        "answer": "H200 提供近乎兩倍的記憶體容量（141GB vs 80GB）和比 H100 多 1.4 倍的記憶體頻寬。在實際基準測試中，這轉化為 Llama 2 70B 等大型語言模型 1.4x-1.9x 更快的推論效能。"
      },
      "q3": {
        "question": "H200 如何增強生成式 AI 和 LLM 開發？",
        "answer": "H200 的大規模記憶體容量和頻寬專為大型語言模型設計。它可以處理更大的批次大小、更長的上下文視窗和更大的模型，而不會受到記憶體限制，實現更快的迭代和更高效的訓練和推論工作流程。"
      },
      "q4": {
        "question": "在 NexusAI 中使用 H200 有什麼好處？",
        "answer": "NexusAI 提供 H200 GPU 的即時存取，採用隨用隨付定價，起價 $2.15/GPU-小時。優勢包括企業 SLA、用於多 GPU 工作負載的 NVLink 連接、預配置的 ML 環境和 24/7 技術支援。"
      },
      "q5": {
        "question": "用戶如何在 NexusAI 上存取 H200 GPU？",
        "answer": "開始使用很簡單：註冊 NexusAI 帳戶，選擇符合您工作負載需求的 H200 GPU 配置，幾分鐘內即可部署。我們的團隊也可以協助自訂配置和企業部署。"
      }
    }
  },
  "gb200Faq": {
    "title": "常見問題",
    "items": {
      "q1": {
        "question": "什麼是 NVIDIA GB200 NVL72，為什麼它是獨特的？",
        "answer": "NVIDIA GB200 NVL72 是下一代 AI 超級運算，在單一機架規模系統中結合 72 個 Blackwell GPU 和 Grace CPU。與前幾代相比，它提供前所未有的 AI 訓練和推論效能，每瓦效能提升高達 30 倍。"
      },
      "q2": {
        "question": "GB200 NVL72 提供哪些效能改進？",
        "answer": "與基於 H100 的系統相比，GB200 NVL72 提供高達 30 倍更快的 AI 推論和 4 倍更快的訓練。憑藉 13.5TB 的統一 HBM3e 記憶體和 130TB/s 的記憶體頻寬，它可以輕鬆處理最大的 AI 模型。"
      },
      "q3": {
        "question": "GB200 NVL72 如何支援可擴展性？",
        "answer": "該系統使用第 5 代 NVLink，具備 1.8TB/s 的 GPU 對 GPU 頻寬，實現整個 72-GPU 系統的無縫擴展。多個 NVL72 機架可以透過高速網路連接以進行更大規模的部署。"
      },
      "q4": {
        "question": "在 NexusAI 中使用 GB200 NVL72 有什麼好處？",
        "answer": "NexusAI 提供完全託管的 GB200 NVL72 基礎設施，包括企業 SLA、專屬支援和靈活的部署選項。用戶無需資本投資即可立即存取，並獲得優化的軟體堆疊和 MLOps 工具。"
      },
      "q5": {
        "question": "用戶如何存取 GB200 NVL72？",
        "answer": "請聯繫我們的銷售團隊討論您的需求並加入我們的優先存取計畫。我們提供靈活的部署選項，包括專屬叢集、預留容量和隨需存取，視您的需求而定。"
      }
    }
  },
  "hgxb200Faq": {
    "title": "常見問題",
    "items": {
      "q1": {
        "question": "什麼是 NVIDIA HGX B200，它用於什麼？",
        "answer": "NVIDIA HGX B200 是一個高效能 AI 運算平台，在單一基板上配備 8 個 Blackwell 架構 GPU。它專為最苛刻的 AI 訓練和推論工作負載設計，包括訓練大型語言模型、生成式 AI 和科學運算應用。"
      },
      "q2": {
        "question": "HGX B200 的效能有什麼獨特之處？",
        "answer": "HGX B200 配備 8 個 Blackwell GPU，可提供高達 144 petaflops 的 AI 效能。每個 GPU 都配備支援 FP4 的下一代 Tensor Core，相比前幾代可實現 4 倍更快的推論。統一的 HBM3e 記憶體池提供 1.4TB 的高頻寬記憶體。"
      },
      "q3": {
        "question": "HGX B200 提供哪些架構優勢？",
        "answer": "該平台配備第 5 代 NVLink，具備 1.8TB/s 的 GPU 對 GPU 頻寬，使所有 8 個 GPU 能夠作為統一運算引擎運作。解壓縮引擎加速資料庫查詢，而 Transformer 引擎自動優化 LLM 工作負載。"
      },
      "q4": {
        "question": "HGX B200 如何確保可擴展性？",
        "answer": "多個 HGX B200 系統可以透過 NVLink Switch 和高速網路連接，創建具有數千個 GPU 的 AI 超級電腦。該架構支援訓練和推論工作負載的線性擴展，非常適合前沿 AI 開發。"
      },
      "q5": {
        "question": "客戶如何存取 HGX B200 平台？",
        "answer": "NexusAI 提供靈活的 HGX B200 基礎設施存取，包括隨需每小時存取、具有批量折扣的預留容量和完全專屬叢集。請聯繫我們的銷售團隊討論您的需求並開始自訂部署。"
      }
    }
  },
  "languages": {
    "en": "English",
    "zh-TW": "繁體中文",
    "ja": "日本語",
    "ko": "한국어"
  }
}